import time

import tensorflow as tf
from IPython import display

from data import generate_and_save_images
from model import make_generator_model, make_discriminator_model
from data import num_examples_to_generate, noise_dim, BATCH_SIZE

# Define models.
generator = make_generator_model()
discriminator = make_discriminator_model()

# This method returns a helper function to compute cross entropy loss.
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

# Set the discriminator loss to the sum of the cross entropy of the real and fake classification.
def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output) * 0.9, real_output) # Label smoothing.
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

# Simple cross entropy for the generator loss.
def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

# Define both models optimizers.
generator_optimizer = tf.keras.optimizers.Adam(1e-3)
discriminator_optimizer = tf.keras.optimizers.Adam(5e-4)

# We feed this into the generator after each epoch to track the progress via a gif.
seed = tf.random.normal([num_examples_to_generate, noise_dim])

# '@tf.function' causes the function to be "compiled".
@tf.function
def train_step(images):
    # Compute random noise for the generator's input.
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    # Compute gradients for generator and discriminator.
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        # Pass the noise to the generator.
        generated_images = generator(noise, training=True)

        # Pass a real image (from the dataset) and a fake image
        # (generated by the generator) to the discriminator.
        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        # Calculate the losses.
        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    # Calculate the gradients for the generator with respect to the generator's loss.
    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)

    # Similarly, calculate the gradients for the discriminator with respect to the discriminator's loss.
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    # Update the generator's weights using the calculated gradients.
    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))

    # Update the discriminator's weights using the calculated gradients.
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

    # Return both generator and discriminator losses for monitoring during training.
    return gen_loss, disc_loss

# Training loop.
def train(dataset, epochs):
    # Initialize lists to keep track of the losses.
    gen_loss_list = []
    disc_loss_list = []

    for epoch in range(epochs):
        start = time.time()

        # Halve the learning rate every 100 epochs.
        if (epoch + 1) % 100 == 0:
            gen_new_lr = generator_optimizer.learning_rate * 0.5
            generator_optimizer.learning_rate.assign(gen_new_lr)

            disc_new_lr = discriminator_optimizer.learning_rate * 0.5
            discriminator_optimizer.learning_rate.assign(disc_new_lr)
            print(f'\n # Learning rate of generator halved to     {gen_new_lr:.7g} at epoch {epoch + 1}')
            print(f'\n # Learning rate of discriminator halved to {disc_new_lr:.7g} at epoch {epoch + 1}')
            
            # Optionally save the models.
            # generator.save('generator.keras')
            # discriminator.save('discriminator.keras')

        # Initialize variables to accumulate losses for this epoch.
        total_gen_loss = 0.0
        total_disc_loss = 0.0
        num_batches = 0

        for image_batch in dataset:
            # Perform training step and capture the losses.
            gen_loss, disc_loss = train_step(image_batch)
            total_gen_loss += gen_loss
            total_disc_loss += disc_loss
            num_batches += 1

        # Average the losses over the number of batches.
        avg_gen_loss = total_gen_loss / num_batches
        avg_disc_loss = total_disc_loss / num_batches

        # Add losses to their lists for tracking progress.
        gen_loss_list.append(avg_gen_loss)
        disc_loss_list.append(avg_disc_loss)

        # Produce images for the GIF as you go
        display.clear_output(wait=True)
        generate_and_save_images(generator, epoch + 1, seed)

        # Print info of the latest epoch in form of time taken and both losses.
        print("\n-----------------------------")
        print('Time for epoch {:4d} is {:5.2f}s'.format(epoch + 1, time.time() - start))
        print('     Generator Loss:      {:.5f}'.format(avg_gen_loss))
        print('     Discriminator Loss:  {:.5f}'.format(avg_disc_loss))


    # Generate after the final epoch.
    display.clear_output(wait=True)
    generate_and_save_images(generator, epochs, seed)

    return gen_loss_list, disc_loss_list